{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook pulls raw data from https://www.sec.gov/data/foiadocsfailsdatahtm\n",
    "# and sanitizes it, afterwards it is exported by year, and as a single csv into the sanitized subfolder\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "def get_or_create_folder(baseDir, folderName):\n",
    "    path = os.path.join(baseDir, folderName)\n",
    "    if(not os.path.exists(path)):\n",
    "        os.mkdir(path)\n",
    "    return path\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "raw_folder = get_or_create_folder(current_dir, 'raw')\n",
    "cns_folder_raw = get_or_create_folder(raw_folder, 'cnsfails')\n",
    "\n",
    "sanitized_folder = get_or_create_folder(current_dir, 'sanitized')\n",
    "cns_folder_sanitized = get_or_create_folder(sanitized_folder, 'cnsfails-txt')\n",
    "csv_yearly = get_or_create_folder(sanitized_folder, 'cnsfails-yearly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "318 files downloaded or already found in the cache\n"
     ]
    }
   ],
   "source": [
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen\n",
    "\n",
    "start_year = 2004\n",
    "start_month = 3\n",
    "end_year = 2021\n",
    "end_month = 10\n",
    "\n",
    "def download_and_unzip(url):\n",
    "    resp = urlopen(url)\n",
    "    zipfile = ZipFile(BytesIO(resp.read()))\n",
    "    zipfile.extractall(path=cns_folder_raw)\n",
    "\n",
    "def download_if_necessary(url, downloaded_files):\n",
    "    if(url not in downloaded_files):\n",
    "        print(\"Download \" + url)\n",
    "        download_and_unzip(url)\n",
    "        downloaded_files.append(url)\n",
    "\n",
    "# Store already downloaded files in a list\n",
    "downloaded_files_path = f\"{cns_folder_raw}/downloaded.txt\"\n",
    "downloaded_files = []\n",
    "if(os.path.exists(downloaded_files_path)):\n",
    "    with open(downloaded_files_path, 'r') as f:\n",
    "        downloaded_files = f.readlines()\n",
    "    downloaded_files = list(map(lambda s: s.strip(), downloaded_files))\n",
    "\n",
    "# download all files in the time range that have not yet been downloaded\n",
    "# Sadly they have quite scrambled naming schemas\n",
    "# Only first entry  https://www.sec.gov/files/data/fails-deliver-data/cnsp_sec_fails_2004q1.zip\n",
    "# Until 2009-06     https://www.sec.gov/files/data/frequently-requested-foia-document-fails-deliver-data/cnsp_sec_fails_2004q2.zip\n",
    "# Until 2017-06a    https://www.sec.gov/files/data/frequently-requested-foia-document-fails-deliver-data/cnsfails201706a.zip\n",
    "# Starting 2017-06b https://www.sec.gov/files/data/fails-deliver-data/cnsfails201706b.zip\n",
    "# Between 2020-02 and 2020-04     https://www.sec.gov/files/node/add/data_distribution/cnsfails202002a.zip\n",
    "base_url_long = \"https://www.sec.gov/files/data/frequently-requested-foia-document-fails-deliver-data/\"\n",
    "base_url_short = \"https://www.sec.gov/files/data/fails-deliver-data/\"\n",
    "base_url_data = \"https://www.sec.gov/files/node/add/data_distribution/\"\n",
    "for year in range(start_year, end_year+1):\n",
    "    start = start_month if (year == start_year) else 1\n",
    "    end = end_month if (year == end_year) else 12\n",
    "    for month in range(start, end+1):\n",
    "        # First entry has a different naming\n",
    "        if(year == 2004 and month <= 3):\n",
    "            if(month == 3):\n",
    "                download_if_necessary(f\"{base_url_short}cnsp_sec_fails_2004q1.zip\", downloaded_files)\n",
    "            continue\n",
    "        \n",
    "        # up to Q2 2009, the files were quarter chunks\n",
    "        if(year < 2009 or (year == 2009 and month <= 6) ):\n",
    "            if(month % 3 == 0):\n",
    "                quarter = int(month/3)\n",
    "                download_if_necessary(f\"{base_url_long}cnsp_sec_fails_{year}q{quarter}.zip\", downloaded_files)\n",
    "            continue\n",
    "\n",
    "        # Special mixed case for 2017-06\n",
    "        if(year == 2017 and month == 6):\n",
    "            download_if_necessary(f\"{base_url_long}cnsfails{year}{month:02d}a.zip\", downloaded_files)\n",
    "            download_if_necessary(f\"{base_url_short}cnsfails{year}{month:02d}b.zip\", downloaded_files)\n",
    "            continue\n",
    "\n",
    "        # Special case 2019-10\n",
    "        if(year == 2019 and month == 10):\n",
    "            download_if_necessary(f\"{base_url_short}cnsfails{year}{month:02d}a_0.zip\", downloaded_files)\n",
    "            download_if_necessary(f\"{base_url_short}cnsfails{year}{month:02d}b.zip\", downloaded_files)\n",
    "            continue\n",
    "\n",
    "        base_url = base_url_long if(year < 2017 or (year == 2017 and month <6)) else base_url_short\n",
    "        #Special case 2020-02 - 2020-04\n",
    "        if(year == 2020 and (month >= 2 and month <= 4)):\n",
    "            base_url = base_url_data\n",
    "\n",
    "        download_if_necessary(f\"{base_url}cnsfails{year}{month:02d}a.zip\", downloaded_files)\n",
    "        download_if_necessary(f\"{base_url}cnsfails{year}{month:02d}b.zip\", downloaded_files)\n",
    "\n",
    "with open(downloaded_files_path, 'w') as f:\n",
    "    f.write(\"\\n\".join(map(str, downloaded_files)))\n",
    "\n",
    "print(f\"{len(downloaded_files)} files downloaded or already found in the cache\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def duplicate_and_truncate_cnsfails(raw_folder, sanitized_folder, name, truncate_target):\n",
    "    # Offset from which we start searching for truncate_target\n",
    "    reading_offset = 100\n",
    "    for path in Path(raw_folder).rglob(f'*{name}*.txt'):\n",
    "        filename = os.path.basename(path)\n",
    "        new_path = os.path.join(sanitized_folder, filename)\n",
    "        shutil.copy2(path, new_path)\n",
    "        with open(new_path, \"r+\", encoding='ISO-8859-1') as file:\n",
    "            # Move the pointer to the end of the file with the defined offset\n",
    "            file.seek(0, os.SEEK_END)\n",
    "            pos = file.tell() - reading_offset\n",
    "            file.seek(pos, os.SEEK_SET)\n",
    "            \n",
    "            # Read the end values to check, if it contains the truncation target\n",
    "            end_text = file.read(reading_offset)\n",
    "            index = end_text.find(truncate_target)\n",
    "            if(index == -1):\n",
    "                continue\n",
    "            end_pos = pos + index\n",
    "            file.seek(end_pos, os.SEEK_SET)\n",
    "\n",
    "            if pos > 0:\n",
    "                file.seek(end_pos, os.SEEK_SET)\n",
    "                file.truncate()\n",
    "\n",
    "duplicate_and_truncate_cnsfails(cns_folder_raw, cns_folder_sanitized, 'cns', 'Trailer record count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sanitize cnsfails cnsp_sec_fails_200408.txt\n",
      "sanitize cnsfails cnsp_sec_fails_200409.txt\n",
      "sanitize cnsfails cnsp_sec_fails_200410.txt\n",
      "sanitize cnsfails cnsp_sec_fails_200411.txt\n",
      "sanitize cnsfails cnsp_sec_fails_200412.txt\n",
      "sanitize cnsfails cnsp_sec_fails_200501.txt\n",
      "sanitize cnsfails cnsfails202104b.txt\n"
     ]
    }
   ],
   "source": [
    "def sanitize_cnsfails_ocr(path):\n",
    "    filename = os.path.basename(path)\n",
    "    print(f\"sanitize cnsfails {filename}\")\n",
    "    raw_cns_fails = []\n",
    "    with open(path, 'r', encoding='ISO-8859-1') as f:\n",
    "        raw_cns_fails = f.readlines()\n",
    "    \n",
    "    sanitized_cns_fails = [line\\\n",
    "        .replace('BAM| ENTMT INC', 'BAM! ENTMT INC')\\\n",
    "        .replace('BRAVO| FOODS INTERNATIONAL CP', 'BRAVO! FOODS INTERNATIONAL CP')\\\n",
    "        .replace('YUM| BRANDS, INC', 'YUM BRANDS, INC')\\\n",
    "        .replace('EZENIA| INC', 'EZENIA! INC')\\\n",
    "        .replace('POW| ENTERTAINMENT INC', 'POW! ENTERTAINMENT INC')\\\n",
    "        .replace('MAKEMUSIC| INC NEW', 'MAKEMUSIC! INC NEW')\\\n",
    "        .replace('DMY TECHNOLOGY GROUP INC IV |', 'DMY TECHNOLOGY GROUP INC IV WT')\\\n",
    "            for line in raw_cns_fails]\n",
    "    \n",
    "    with open(path, 'w') as f:\n",
    "        f.write(\"\".join(sanitized_cns_fails))\n",
    "\n",
    "# Those are all files we found that have wrong entries that add a pipe (and therefore breaking the csv)\n",
    "# The fails in the data probably come from OCR problems  matching a ! to a | instead\n",
    "broken_files = ['cnsp_sec_fails_200408.txt', 'cnsp_sec_fails_200409.txt', 'cnsp_sec_fails_200410.txt', \\\n",
    "    'cnsp_sec_fails_200411.txt', 'cnsp_sec_fails_200412.txt', 'cnsp_sec_fails_200501.txt', 'cnsfails202104b.txt']\n",
    "for filename in broken_files:\n",
    "    path = os.path.join(cns_folder_sanitized, filename)\n",
    "    sanitize_cnsfails_ocr(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading all files in memory for pandas, this will take some time\n",
      "50 files read\n",
      "100 files read\n",
      "150 files read\n",
      "200 files read\n",
      "250 files read\n",
      "300 files read\n",
      "350 files read\n",
      "All 360 files read, generating dataframe\n",
      "dataframe generated\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SETTLEMENT DATE     21348881\n",
       "CUSIP               21348881\n",
       "SYMBOL              21348871\n",
       "QUANTITY (FAILS)    21348881\n",
       "DESCRIPTION         21348881\n",
       "PRICE               21348881\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_float(x):\n",
    "    if not x or  x == '.':\n",
    "        return 0.0\n",
    "    try:\n",
    "        return float(x)   \n",
    "    except:        \n",
    "        print(f\"Can't convert {x} to float\")\n",
    "        return 0.0\n",
    "\n",
    "def read_csv(folder, name):\n",
    "    li = []\n",
    "    counter = 0\n",
    "    print(f\"Reading all files in memory for pandas, this will take some time\")\n",
    "    for path in Path(folder).rglob(f'*{name}*.txt'):\n",
    "        csv_df = pd.read_csv(path, index_col=None, header=0, sep ='|', encoding = 'ISO-8859-1', parse_dates=['SETTLEMENT DATE'],\\\n",
    "            converters={'PRICE': convert_float},\\\n",
    "            dtype={'CUSIP': 'str', 'SYMBOL': 'str', 'QUANTITY (FAILS)': 'int', 'DESCRIPTION': 'str'})\n",
    "        li.append(csv_df)\n",
    "        counter = counter+1\n",
    "        if(counter % 50 == 0):\n",
    "            print(f\"{counter} files read\")\n",
    "    print(f\"All {counter} files read, generating dataframe\")\n",
    "    df = pd.concat(li, axis=0, ignore_index=True)\n",
    "    print(f\"dataframe generated\")\n",
    "    return df\n",
    "\n",
    "df = read_csv(cns_folder_sanitized, 'cns')\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>SYMBOL</th>\n",
       "      <th>FAILS</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16834021</th>\n",
       "      <td>2004-03-22</td>\n",
       "      <td>866</td>\n",
       "      <td>13000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16831725</th>\n",
       "      <td>2004-03-22</td>\n",
       "      <td>AAC</td>\n",
       "      <td>613985</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16831839</th>\n",
       "      <td>2004-03-22</td>\n",
       "      <td>AACS</td>\n",
       "      <td>92968</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16831717</th>\n",
       "      <td>2004-03-22</td>\n",
       "      <td>AAII</td>\n",
       "      <td>522948</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16831835</th>\n",
       "      <td>2004-03-22</td>\n",
       "      <td>AAMI</td>\n",
       "      <td>73220</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               DATE SYMBOL   FAILS  PRICE\n",
       "16834021 2004-03-22    866   13000    0.0\n",
       "16831725 2004-03-22    AAC  613985    0.0\n",
       "16831839 2004-03-22   AACS   92968    0.0\n",
       "16831717 2004-03-22   AAII  522948    0.0\n",
       "16831835 2004-03-22   AAMI   73220    0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.rename(columns={\"QUANTITY (FAILS)\": \"FAILS\"})\n",
    "df = df.rename(columns={\"SETTLEMENT DATE\": \"DATE\"})\n",
    "df = df[['DATE', 'SYMBOL', 'FAILS', 'PRICE']]\n",
    "df = df.sort_values(by=['DATE', 'SYMBOL'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing cnsfails-2004.csv to output folder\n",
      "Storing cnsfails-2005.csv to output folder\n",
      "Storing cnsfails-2006.csv to output folder\n",
      "Storing cnsfails-2007.csv to output folder\n",
      "Storing cnsfails-2008.csv to output folder\n",
      "Storing cnsfails-2009.csv to output folder\n",
      "Storing cnsfails-2010.csv to output folder\n",
      "Storing cnsfails-2011.csv to output folder\n",
      "Storing cnsfails-2012.csv to output folder\n",
      "Storing cnsfails-2013.csv to output folder\n",
      "Storing cnsfails-2014.csv to output folder\n",
      "Storing cnsfails-2015.csv to output folder\n",
      "Storing cnsfails-2016.csv to output folder\n",
      "Storing cnsfails-2017.csv to output folder\n",
      "Storing cnsfails-2018.csv to output folder\n",
      "Storing cnsfails-2019.csv to output folder\n",
      "Storing cnsfails-2020.csv to output folder\n",
      "Storing cnsfails-2021.csv to output folder\n",
      "Storing cnsfails-200403-202110.csv to output folder\n"
     ]
    }
   ],
   "source": [
    "def store_csv(df, filename, folder):\n",
    "    print(f\"Storing {filename} to output folder\")\n",
    "    fullpath = os.path.join(folder, filename)\n",
    "    df.to_csv(fullpath, index=False, sep =',', decimal='.')\n",
    "\n",
    "def store_csv_by_year(df, folder, start_year, end_year):\n",
    "    for year in range(start_year, end_year+1):\n",
    "        df_year=df[df['DATE'].dt.year == year]\n",
    "        store_csv(df_year, f\"cnsfails-{year}.csv\", folder)\n",
    "\n",
    "store_csv_by_year(df, csv_yearly, start_year, end_year)\n",
    "store_csv(df, f\"cnsfails-{start_year}{start_month:02d}-{end_year}{end_month:02d}.csv\", sanitized_folder)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "226b0bfe565b1b26ba0fac29fd4d427cb0aeca81c7a6f675349b9931f46b38c7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "metadata": {
   "interpreter": {
    "hash": "226b0bfe565b1b26ba0fac29fd4d427cb0aeca81c7a6f675349b9931f46b38c7"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
